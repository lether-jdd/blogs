node由于V8内存分配机制造成内存有限，读写大文件时内存吃紧，
流中的数据可能不会立刻就全部可用，并且你无需一次性地把这些数据全部放入内存
1 读写大文件时使用流？
2 

stream读写和正常文件读写

所有的流都是EventEmitter的实例

stream中流动的数据就是buffer类型（二进制数据）
无论用stream读取文件还是fs.readFile读取文件，读出来的都应该是二进制格式
# 1 流的来源
控制台输入:process.stdin
http请求
读取文件
# 2 流监听的事件
"data","end","opne","close","error"等事件
# 3 管道
source.pipe(dest)
所有执行文件操作的场景，都应该尝试使用 stream ，例如文件的读写、拷贝、压缩、解压、格式转换等。除非是体积很小的文件，而且读写次数很少，性能上被忽略。如果是体积很大或者读写次数很多的情况下，建议使用stream来优化性能
# 4 逐行
readline最常见的使用应该是日志的逐行分析
# 5 stream种类
可读、可写、双工、转换流
转换流：是双工流的一种，它的输出与输入是相关联的,只有触发了写入操作时才会进入_transform方法中